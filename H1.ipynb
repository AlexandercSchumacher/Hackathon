{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920ef7bb-0e31-4151-9fb0-50de1141d91e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffe1f7f4ada8c4a3160626f214fc1e36",
     "grade": false,
     "grade_id": "cell-48cccda20e73351e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Hackathon: From Raw Data to ML-Ready Dataset\n",
    "## Insight-Driven EDA and End-to-End Feature Engineering on Airbnb Data Using pandas and Plotly\n",
    "\n",
    "### What is a Hackathon?\n",
    "\n",
    "A hackathon is a fast-paced, collaborative event where participants use data and technology to solve a real problem end-to-end.  \n",
    "In this hackathon, you will work with a **real-world Airbnb dataset** and complete two interconnected goals:\n",
    "\n",
    "- Produce a **high-quality exploratory data analysis (EDA)** using `pandas` and `plotly`, extracting meaningful insights, trends, and signals from the data.  \n",
    "- Design and deliver a **clean, feature-rich, ML-ready dataset** that will serve as the foundation for a follow-up hackathon focused on building and evaluating machine learning models.\n",
    "\n",
    "Your task is to **get the most out of the data**: uncover structure and patterns through EDA, and engineer informative features (numerical, categorical, temporal, textual (TF–IDF), and optionally image-based) to maximize the predictive power of the final dataset.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>About the Dataset</b>\n",
    "\n",
    "<u>Context</u>\n",
    "\n",
    "The data comes from <a href=\"https://insideairbnb.com/get-the-data/\">Inside Airbnb</a>, an open project that publishes detailed, regularly updated datasets for cities around the world.  \n",
    "Each city provides three main CSV files:\n",
    "\n",
    "- <b>listings.csv</b> — property characteristics, host profiles, descriptions, amenities, etc.  \n",
    "- <b>calendar.csv</b> — daily availability and pricing information for each listing.  \n",
    "- <b>reviews.csv</b> — guest feedback and textual reviews.\n",
    "\n",
    "These datasets offer a rich view of the short-term rental market, including availability patterns, pricing behavior, host attributes, and guest sentiment.  \n",
    "\n",
    "<u>Inspiration</u>\n",
    "\n",
    "Your ultimate objective is to create a dataset suitable for training a machine learning model that predicts whether a specific Airbnb listing will be <b>available on a given date</b>, using property attributes, review information, and host characteristics.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Task</b>\n",
    "\n",
    "Using one city of your choice from Inside Airbnb, create an end-to-end pipeline that:\n",
    "\n",
    "1. Loads and explores the raw data (EDA).  \n",
    "2. Engineers features (numerical, categorical, temporal, textual TF–IDF, etc.).  \n",
    "3. Builds a unified ML-ready dataset.  \n",
    "\n",
    "Please remember to add comments explaining your decisions. Comments help us understand your thought process and ensure accurate evaluation of your work. This assignment requires code-based solutions—**manually calculated or hard-coded results will not be accepted**. Thoughtful comments and visualizations are encouraged and will be highly valued.\n",
    "\n",
    "- Write your solution directly in this notebook, modifying it as needed.\n",
    "- Once completed, submit the notebook in **.ipynb** format via Moodle.\n",
    "    \n",
    "<b>Collaboration Requirement: Git & GitHub</b>\n",
    "\n",
    "You must collaborate with your team using a **shared GitHub repository**.  \n",
    "Your use of Git is part of the evaluation. We will specifically look at:\n",
    "\n",
    "- Commit quality (clear messages, meaningful steps).  \n",
    "- Balanced participation across team members.  \n",
    "- Use of branches.  \n",
    "- Ability to resolve merge conflicts appropriately.  \n",
    "- A clean, readable project history that reflects real collaboration.\n",
    "\n",
    "Good Git practice is **part of your grade**, not optional.\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "    You are free to add as many cells as you wish as long as you leave untouched the first one.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Hints</b>\n",
    "\n",
    "- Text columns often carry substantial predictive power, use text-vectorization methods to extract meaningful features.  \n",
    "- Make sure all columns use appropriate data types (categorical, numeric, datetime, boolean). Correct dtypes help prevent subtle bugs and improve performance.  \n",
    "- Feel free to enrich the dataset with any additional information you consider useful: engineered features, external data, derived temporal features, etc.  \n",
    "- If the dataset is too large for your computer, use <code>.sample()</code> to work with a subset while preserving the logic of your pipeline.  \n",
    "- Plotly offers a wide variety of powerful visualizations, experiment creatively, but always begin with a clear analytical question: *What insight am I trying to uncover with this plot?*\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Submission Deadline:</b> Wednesday, December 3rd, 12:00\n",
    "\n",
    "Start with a simple, working pipeline.  \n",
    "Do not over-complicate your code too much. Start with a simple working solution and refine it if you have time.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "You may add as many cells as you want, but the **first cell must remain exactly as provided**. Do not edit, move, or delete it under any circumstances.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da41098",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8431230dc8647851888c39d82eb7078d",
     "grade": true,
     "grade_id": "ex1",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# LEAVE BLANK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84467c34-1fa2-4f03-b7ba-e216836ff6b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bce797b7aa5f22189e671fd29fa5841",
     "grade": false,
     "grade_id": "cell-140b4c12d85796ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Team Information\n",
    "\n",
    "Fill in the information below.  \n",
    "All fields are **mandatory**.\n",
    "\n",
    "- **GitHub Repository URL**: Paste the link to the team repo you will use for collaboration.\n",
    "- **Team Members**: List all student names (and emails or IDs if required).\n",
    "\n",
    "Do not modify the section title.  \n",
    "Do not remove this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "907a430c-3e17-42e4-9b63-3bafd596c383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', [])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Team Information (Mandatory) ===\n",
    "# Fill in the fields below.\n",
    "\n",
    "GITHUB_REPO = \"\"       # e.g. \"https://github.com/myteam/airbnb-hackathon\"\n",
    "TEAM_MEMBERS = [\n",
    "    # \"Full Name 1\",\n",
    "    # \"Full Name 2\",\n",
    "    # \"Full Name 3\",\n",
    "]\n",
    "\n",
    "GITHUB_REPO, TEAM_MEMBERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "026225cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           listing_id        date available  price  adjusted_price  \\\n",
      "0  686088974677118082  2025-06-27         f    NaN             NaN   \n",
      "1  686088974677118082  2025-06-28         f    NaN             NaN   \n",
      "2  686088974677118082  2025-06-29         t    NaN             NaN   \n",
      "3  686088974677118082  2025-06-30         t    NaN             NaN   \n",
      "4  686088974677118082  2025-07-01         t    NaN             NaN   \n",
      "\n",
      "   minimum_nights  maximum_nights  \n",
      "0               2            1125  \n",
      "1               2            1125  \n",
      "2               2            1125  \n",
      "3               2            1125  \n",
      "4               2            1125  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "calendar = pd.read_csv(\"../Data/calendar.csv.gz\", compression=\"gzip\")\n",
    "print(calendar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06dfb713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                          listing_url       scrape_id last_scraped  \\\n",
      "0  155305  https://www.airbnb.com/rooms/155305  20250617145515   2025-06-17   \n",
      "1  197263  https://www.airbnb.com/rooms/197263  20250617145515   2025-06-17   \n",
      "2  209068  https://www.airbnb.com/rooms/209068  20250617145515   2025-06-17   \n",
      "3  246315  https://www.airbnb.com/rooms/246315  20250617145515   2025-06-17   \n",
      "4  314540  https://www.airbnb.com/rooms/314540  20250617145515   2025-06-17   \n",
      "\n",
      "        source                                               name  \\\n",
      "0  city scrape                 Cottage! BonPaul + Sharky's Hostel   \n",
      "1  city scrape                       Tranquil Room & Private Bath   \n",
      "2  city scrape                                    Terrace Cottage   \n",
      "3  city scrape                          Asheville Dreamer's Cabin   \n",
      "4  city scrape  Asheville Urban Farmhouse Entire Home 4.6 mi t...   \n",
      "\n",
      "                                         description  \\\n",
      "0  West Asheville Cottage within walking distance...   \n",
      "1  This is a comfy, peaceful and clean room with ...   \n",
      "2  Located in one of Asheville's oldest historic ...   \n",
      "3  Hi there,<br />I am usually here half of each ...   \n",
      "4  Farmhouse in the city is OPEN! This charming 1...   \n",
      "\n",
      "                               neighborhood_overview  \\\n",
      "0  We are within easy walk of pubs, breweries, mu...   \n",
      "1                                                NaN   \n",
      "2  Our beautiful Grove Park Historic District clo...   \n",
      "3                                                NaN   \n",
      "4  City vibes with country appeal. Peaceful neigh...   \n",
      "\n",
      "                                         picture_url  host_id  ...  \\\n",
      "0  https://a0.muscache.com/pictures/hosting/Hosti...   746673  ...   \n",
      "1  https://a0.muscache.com/pictures/miso/Hosting-...   961396  ...   \n",
      "2  https://a0.muscache.com/pictures/1829924/9f3bf...  1029919  ...   \n",
      "3  https://a0.muscache.com/pictures/5908617/cfe79...  1292070  ...   \n",
      "4  https://a0.muscache.com/pictures/hosting/Hosti...   381660  ...   \n",
      "\n",
      "  review_scores_communication review_scores_location review_scores_value  \\\n",
      "0                        4.74                   4.92                4.58   \n",
      "1                        4.93                   4.86                4.98   \n",
      "2                        4.98                   4.94                4.80   \n",
      "3                        4.65                   4.67                4.59   \n",
      "4                        4.97                   4.91                4.94   \n",
      "\n",
      "  license instant_bookable calculated_host_listings_count  \\\n",
      "0     NaN                t                              8   \n",
      "1     NaN                f                              2   \n",
      "2     NaN                f                              1   \n",
      "3     NaN                f                              3   \n",
      "4     NaN                t                              1   \n",
      "\n",
      "  calculated_host_listings_count_entire_homes  \\\n",
      "0                                           2   \n",
      "1                                           1   \n",
      "2                                           1   \n",
      "3                                           2   \n",
      "4                                           1   \n",
      "\n",
      "  calculated_host_listings_count_private_rooms  \\\n",
      "0                                            3   \n",
      "1                                            1   \n",
      "2                                            0   \n",
      "3                                            1   \n",
      "4                                            0   \n",
      "\n",
      "  calculated_host_listings_count_shared_rooms reviews_per_month  \n",
      "0                                           3              2.69  \n",
      "1                                           0              0.56  \n",
      "2                                           0              0.40  \n",
      "3                                           0              0.32  \n",
      "4                                           0              0.22  \n",
      "\n",
      "[5 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "listings_gz = pd.read_csv(\"../Data/listings.csv.gz\", compression=\"gzip\")\n",
    "print(listings_gz.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100ee041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   listing_id       id        date  reviewer_id reviewer_name  \\\n",
      "0      155305   409437  2011-07-31       844309       Jillian   \n",
      "1      155305   469775  2011-08-23       343443         Katie   \n",
      "2      155305   548257  2011-09-19      1152025         Katie   \n",
      "3      155305   671470  2011-10-28      1245885         Jason   \n",
      "4      155305  1606327  2012-07-01      1891395         Craig   \n",
      "\n",
      "                                            comments  \n",
      "0  We had a wonderful time! The cottage was very ...  \n",
      "1  Place was great! Can't really speak to the ins...  \n",
      "2  We had a great time!  The cabin was nice and a...  \n",
      "3  Clean and comfortable room with everything you...  \n",
      "4  The cabin was solid for an overnight stay. It ...  \n"
     ]
    }
   ],
   "source": [
    "reviews_gz = pd.read_csv(\"../Data/reviews.csv.gz\", compression=\"gzip\")\n",
    "print(reviews_gz.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "370376ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                type                                           features\n",
      "0  FeatureCollection  {'type': 'Feature', 'geometry': {'type': 'Mult...\n",
      "1  FeatureCollection  {'type': 'Feature', 'geometry': {'type': 'Mult...\n",
      "2  FeatureCollection  {'type': 'Feature', 'geometry': {'type': 'Mult...\n",
      "3  FeatureCollection  {'type': 'Feature', 'geometry': {'type': 'Mult...\n",
      "4  FeatureCollection  {'type': 'Feature', 'geometry': {'type': 'Mult...\n"
     ]
    }
   ],
   "source": [
    "neighbourhoods_geo = pd.read_json(\"../Data/neighbourhoods.geojson\")\n",
    "print(neighbourhoods_geo.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b167bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                               name  host_id  \\\n",
      "0  155305                 Cottage! BonPaul + Sharky's Hostel   746673   \n",
      "1  197263                       Tranquil Room & Private Bath   961396   \n",
      "2  209068                                    Terrace Cottage  1029919   \n",
      "3  246315                          Asheville Dreamer's Cabin  1292070   \n",
      "4  314540  Asheville Urban Farmhouse Entire Home 4.6 mi t...   381660   \n",
      "\n",
      "  host_name  neighbourhood_group  neighbourhood   latitude  longitude  \\\n",
      "0   BonPaul                  NaN          28806  35.578640 -82.595780   \n",
      "1   Timothy                  NaN          28806  35.577350 -82.638040   \n",
      "2     Kevin                  NaN          28804  35.617641 -82.551819   \n",
      "3     Annie                  NaN          28805  35.596150 -82.506350   \n",
      "4       Tom                  NaN          28806  35.585610 -82.627310   \n",
      "\n",
      "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
      "0  Entire home/apt   95.0               1                454  2025-06-14   \n",
      "1     Private room   44.0               2                 87  2024-09-08   \n",
      "2  Entire home/apt   90.0              30                 67  2025-05-03   \n",
      "3     Private room   61.0               7                 53  2019-10-30   \n",
      "4  Entire home/apt  200.0               1                 35  2025-06-13   \n",
      "\n",
      "   reviews_per_month  calculated_host_listings_count  availability_365  \\\n",
      "0               2.69                               8               162   \n",
      "1               0.56                               2                73   \n",
      "2               0.40                               1               268   \n",
      "3               0.32                               3                62   \n",
      "4               0.22                               1               139   \n",
      "\n",
      "   number_of_reviews_ltm  license  \n",
      "0                     16      NaN  \n",
      "1                      5      NaN  \n",
      "2                      2      NaN  \n",
      "3                      0      NaN  \n",
      "4                     11      NaN  \n"
     ]
    }
   ],
   "source": [
    "listings = pd.read_csv(\"../Data/listings.csv\")\n",
    "print(listings.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05374e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   listing_id        date\n",
      "0      155305  2011-07-31\n",
      "1      155305  2011-08-23\n",
      "2      155305  2011-09-19\n",
      "3      155305  2011-10-28\n",
      "4      155305  2012-07-01\n"
     ]
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"../Data/reviews.csv\")\n",
    "print(reviews.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7f0279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   neighbourhood_group  neighbourhood\n",
      "0                  NaN          28704\n",
      "1                  NaN          28715\n",
      "2                  NaN          28732\n",
      "3                  NaN          28801\n",
      "4                  NaN          28803\n"
     ]
    }
   ],
   "source": [
    "neighbourhoods = pd.read_csv(\"../Data/neighbourhoods.csv\")\n",
    "print(neighbourhoods.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: DATA EXPLORATION AND MISSING VALUES ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check data shapes\n",
    "print(\"\\n1. DATA SHAPES:\")\n",
    "print(f\"   Calendar: {calendar.shape}\")\n",
    "print(f\"   Listings (gz): {listings_gz.shape}\")\n",
    "print(f\"   Listings (csv): {listings.shape}\")\n",
    "print(f\"   Reviews (gz): {reviews_gz.shape}\")\n",
    "print(f\"   Reviews (csv): {reviews.shape}\")\n",
    "print(f\"   Neighbourhoods: {neighbourhoods.shape}\")\n",
    "\n",
    "# Use the gzipped versions as they seem more complete\n",
    "listings_df = listings_gz.copy()\n",
    "reviews_df = reviews_gz.copy()\n",
    "\n",
    "# Rename 'id' to 'listing_id' for consistency across datasets\n",
    "if 'id' in listings_df.columns:\n",
    "    listings_df = listings_df.rename(columns={'id': 'listing_id'})\n",
    "\n",
    "# Check missing values in calendar\n",
    "print(\"\\n2. MISSING VALUES IN CALENDAR:\")\n",
    "print(calendar.isnull().sum())\n",
    "print(f\"\\n   Total missing values: {calendar.isnull().sum().sum()}\")\n",
    "print(f\"   Missing percentage: {(calendar.isnull().sum().sum() / calendar.size * 100):.2f}%\")\n",
    "\n",
    "# Check missing values in listings\n",
    "print(\"\\n3. MISSING VALUES IN LISTINGS:\")\n",
    "missing_listings = listings_df.isnull().sum()\n",
    "missing_listings_pct = (missing_listings / len(listings_df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_listings,\n",
    "    'Missing %': missing_listings_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "print(f\"\\n   Columns with missing values: {len(missing_df)}\")\n",
    "print(f\"   Total missing values: {listings_df.isnull().sum().sum()}\")\n",
    "print(\"\\n   Top 20 columns with most missing values:\")\n",
    "print(missing_df.head(20))\n",
    "\n",
    "# Check missing values in reviews\n",
    "print(\"\\n4. MISSING VALUES IN REVIEWS:\")\n",
    "print(reviews_df.isnull().sum())\n",
    "print(f\"\\n   Total missing values: {reviews_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\n5. CALENDAR DATA TYPES:\")\n",
    "print(calendar.dtypes)\n",
    "print(\"\\n   Unique listings in calendar:\", calendar['listing_id'].nunique())\n",
    "print(\"   Date range:\", calendar['date'].min(), \"to\", calendar['date'].max())\n",
    "print(\"   Available values:\", calendar['available'].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b01f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 2: EXPLORATORY DATA ANALYSIS (EDA) WITH VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "# Convert date column to datetime\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "calendar['available_bool'] = calendar['available'] == 't'\n",
    "\n",
    "# Convert price columns - remove $ and commas, convert to float\n",
    "def clean_price(price_str):\n",
    "    if pd.isna(price_str):\n",
    "        return np.nan\n",
    "    if isinstance(price_str, str):\n",
    "        return float(price_str.replace('$', '').replace(',', ''))\n",
    "    return float(price_str)\n",
    "\n",
    "calendar['price_clean'] = calendar['price'].apply(clean_price)\n",
    "calendar['adjusted_price_clean'] = calendar['adjusted_price'].apply(clean_price)\n",
    "\n",
    "# 1. Availability over time\n",
    "print(\"=\" * 80)\n",
    "print(\"EDA: AVAILABILITY PATTERNS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Daily availability rate\n",
    "daily_availability = calendar.groupby('date').agg({\n",
    "    'available_bool': ['mean', 'count']\n",
    "}).reset_index()\n",
    "daily_availability.columns = ['date', 'availability_rate', 'total_listings']\n",
    "\n",
    "fig1 = px.line(\n",
    "    daily_availability, \n",
    "    x='date', \n",
    "    y='availability_rate',\n",
    "    title='Daily Availability Rate Over Time',\n",
    "    labels={'availability_rate': 'Availability Rate', 'date': 'Date'}\n",
    ")\n",
    "fig1.update_layout(height=500, showlegend=False)\n",
    "fig1.show()\n",
    "\n",
    "# 2. Price distribution (when available)\n",
    "price_available = calendar[calendar['available_bool'] & calendar['price_clean'].notna()]['price_clean']\n",
    "\n",
    "fig2 = px.histogram(\n",
    "    price_available,\n",
    "    nbins=50,\n",
    "    title='Price Distribution for Available Listings',\n",
    "    labels={'value': 'Price ($)', 'count': 'Frequency'}\n",
    ")\n",
    "fig2.update_layout(height=500)\n",
    "fig2.show()\n",
    "\n",
    "print(f\"\\nPrice Statistics (available listings):\")\n",
    "print(f\"   Mean: ${price_available.mean():.2f}\")\n",
    "print(f\"   Median: ${price_available.median():.2f}\")\n",
    "print(f\"   Min: ${price_available.min():.2f}\")\n",
    "print(f\"   Max: ${price_available.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Listings analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EDA: LISTINGS CHARACTERISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Room type distribution\n",
    "if 'room_type' in listings_df.columns:\n",
    "    room_type_counts = listings_df['room_type'].value_counts()\n",
    "    fig3 = px.pie(\n",
    "        values=room_type_counts.values,\n",
    "        names=room_type_counts.index,\n",
    "        title='Distribution of Room Types'\n",
    "    )\n",
    "    fig3.update_layout(height=500)\n",
    "    fig3.show()\n",
    "    print(\"\\nRoom Type Distribution:\")\n",
    "    print(room_type_counts)\n",
    "\n",
    "# Price distribution in listings\n",
    "if 'price' in listings_df.columns:\n",
    "    # Clean price in listings\n",
    "    listings_df['price_clean'] = listings_df['price'].apply(clean_price)\n",
    "    price_listings = listings_df[listings_df['price_clean'].notna()]['price_clean']\n",
    "    \n",
    "    fig4 = px.histogram(\n",
    "        price_listings,\n",
    "        nbins=50,\n",
    "        title='Listing Price Distribution',\n",
    "        labels={'value': 'Price ($)', 'count': 'Frequency'}\n",
    "    )\n",
    "    fig4.update_layout(height=500)\n",
    "    fig4.show()\n",
    "\n",
    "# Number of reviews distribution\n",
    "if 'number_of_reviews' in listings_df.columns:\n",
    "    fig5 = px.histogram(\n",
    "        listings_df['number_of_reviews'],\n",
    "        nbins=50,\n",
    "        title='Distribution of Number of Reviews',\n",
    "        labels={'number_of_reviews': 'Number of Reviews', 'count': 'Frequency'}\n",
    "    )\n",
    "    fig5.update_layout(height=500)\n",
    "    fig5.show()\n",
    "\n",
    "# Review scores if available\n",
    "review_score_cols = [col for col in listings_df.columns if 'review_scores' in col.lower()]\n",
    "if review_score_cols:\n",
    "    print(f\"\\nReview Score Columns Found: {review_score_cols}\")\n",
    "    for col in review_score_cols[:3]:  # Show first 3\n",
    "        if listings_df[col].notna().sum() > 0:\n",
    "            fig = px.histogram(\n",
    "                listings_df[col].dropna(),\n",
    "                nbins=20,\n",
    "                title=f'Distribution of {col}',\n",
    "                labels={col: col.replace('_', ' ').title(), 'count': 'Frequency'}\n",
    "            )\n",
    "            fig.update_layout(height=400)\n",
    "            fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Temporal patterns - day of week, month effects\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EDA: TEMPORAL PATTERNS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "calendar['day_of_week'] = calendar['date'].dt.day_name()\n",
    "calendar['month'] = calendar['date'].dt.month\n",
    "calendar['day_of_month'] = calendar['date'].dt.day\n",
    "calendar['is_weekend'] = calendar['date'].dt.dayofweek >= 5\n",
    "\n",
    "# Availability by day of week\n",
    "dow_availability = calendar.groupby('day_of_week')['available_bool'].mean().reset_index()\n",
    "dow_availability.columns = ['day_of_week', 'availability_rate']\n",
    "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_availability['day_of_week'] = pd.Categorical(dow_availability['day_of_week'], categories=dow_order, ordered=True)\n",
    "dow_availability = dow_availability.sort_values('day_of_week')\n",
    "\n",
    "fig6 = px.bar(\n",
    "    dow_availability,\n",
    "    x='day_of_week',\n",
    "    y='availability_rate',\n",
    "    title='Average Availability Rate by Day of Week',\n",
    "    labels={'availability_rate': 'Availability Rate', 'day_of_week': 'Day of Week'}\n",
    ")\n",
    "fig6.update_layout(height=500, xaxis_tickangle=-45)\n",
    "fig6.show()\n",
    "\n",
    "# Availability by month\n",
    "month_availability = calendar.groupby('month')['available_bool'].mean().reset_index()\n",
    "month_availability.columns = ['month', 'availability_rate']\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "month_availability['month_name'] = month_availability['month'].apply(lambda x: month_names[x-1])\n",
    "\n",
    "fig7 = px.bar(\n",
    "    month_availability,\n",
    "    x='month_name',\n",
    "    y='availability_rate',\n",
    "    title='Average Availability Rate by Month',\n",
    "    labels={'availability_rate': 'Availability Rate', 'month_name': 'Month'}\n",
    ")\n",
    "fig7.update_layout(height=500)\n",
    "fig7.show()\n",
    "\n",
    "# Weekend vs weekday\n",
    "weekend_availability = calendar.groupby('is_weekend')['available_bool'].mean()\n",
    "print(f\"\\nWeekend Availability Rate: {weekend_availability[True]:.3f}\")\n",
    "print(f\"Weekday Availability Rate: {weekend_availability[False]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b95d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 3: FEATURE ENGINEERING - NUMERICAL FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE ENGINEERING: NUMERICAL FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Start with listings features\n",
    "features_list = []\n",
    "\n",
    "# 1. Basic listing numerical features\n",
    "if 'id' in listings_df.columns:\n",
    "    # Rename id to listing_id for merging\n",
    "    listings_df = listings_df.rename(columns={'id': 'listing_id'})\n",
    "\n",
    "# Select key numerical features from listings\n",
    "numerical_features = [\n",
    "    'latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', \n",
    "    'beds', 'price', 'minimum_nights', 'maximum_nights', 'number_of_reviews',\n",
    "    'reviews_per_month', 'calculated_host_listings_count', 'availability_365',\n",
    "    'number_of_reviews_ltm'\n",
    "]\n",
    "\n",
    "# Add any review score columns\n",
    "review_score_cols = [col for col in listings_df.columns if 'review_scores' in col.lower()]\n",
    "numerical_features.extend(review_score_cols)\n",
    "\n",
    "# Extract numerical features\n",
    "listing_numerical = listings_df[['listing_id'] + [f for f in numerical_features if f in listings_df.columns]].copy()\n",
    "\n",
    "# Clean price\n",
    "if 'price' in listing_numerical.columns:\n",
    "    listing_numerical['price'] = listing_numerical['price'].apply(clean_price)\n",
    "\n",
    "# Handle missing values in numerical features - fill with median\n",
    "for col in listing_numerical.columns:\n",
    "    if col != 'listing_id' and listing_numerical[col].dtype in ['float64', 'int64']:\n",
    "        median_val = listing_numerical[col].median()\n",
    "        missing_count = listing_numerical[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            listing_numerical[col].fillna(median_val, inplace=True)\n",
    "            print(f\"   Filled {missing_count} missing values in {col} with median: {median_val:.2f}\")\n",
    "\n",
    "# 2. Aggregate features from calendar\n",
    "print(\"\\nCreating calendar-based numerical features...\")\n",
    "\n",
    "calendar_features = calendar.groupby('listing_id').agg({\n",
    "    'available_bool': ['mean', 'sum', 'count'],\n",
    "    'price_clean': ['mean', 'median', 'std', 'min', 'max'],\n",
    "    'minimum_nights': ['mean', 'min', 'max'],\n",
    "    'maximum_nights': ['mean', 'min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "calendar_features.columns = ['listing_id', \n",
    "                            'avg_availability_rate', 'total_available_days', 'total_calendar_days',\n",
    "                            'avg_price', 'median_price', 'price_std', 'min_price', 'max_price',\n",
    "                            'avg_min_nights', 'min_min_nights', 'max_min_nights',\n",
    "                            'avg_max_nights', 'min_max_nights', 'max_max_nights']\n",
    "\n",
    "# Fill missing values\n",
    "calendar_features = calendar_features.fillna(0)\n",
    "\n",
    "print(f\"   Created {len(calendar_features.columns) - 1} calendar-based features\")\n",
    "\n",
    "# 3. Merge listing and calendar numerical features\n",
    "features_numerical = listing_numerical.merge(calendar_features, on='listing_id', how='left')\n",
    "features_numerical = features_numerical.fillna(0)\n",
    "\n",
    "print(f\"\\nTotal numerical features created: {len(features_numerical.columns) - 1}\")\n",
    "print(f\"Shape: {features_numerical.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 4: FEATURE ENGINEERING - CATEGORICAL FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE ENGINEERING: CATEGORICAL FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Extract categorical features from listings\n",
    "categorical_features = ['room_type', 'neighbourhood', 'neighbourhood_group']\n",
    "\n",
    "# Add host-related categorical features if available\n",
    "host_cat_features = [col for col in listings_df.columns if 'host_' in col.lower() and \n",
    "                     listings_df[col].dtype == 'object' and col not in ['host_id', 'host_name']]\n",
    "categorical_features.extend(host_cat_features[:5])  # Limit to first 5 to avoid too many\n",
    "\n",
    "# Extract categorical features\n",
    "listing_categorical = listings_df[['listing_id'] + [f for f in categorical_features if f in listings_df.columns]].copy()\n",
    "\n",
    "# Handle missing values - fill with 'unknown'\n",
    "for col in listing_categorical.columns:\n",
    "    if col != 'listing_id':\n",
    "        missing_count = listing_categorical[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            listing_categorical[col].fillna('unknown', inplace=True)\n",
    "            print(f\"   Filled {missing_count} missing values in {col} with 'unknown'\")\n",
    "\n",
    "# One-hot encode categorical features\n",
    "print(\"\\nOne-hot encoding categorical features...\")\n",
    "features_categorical = pd.get_dummies(listing_categorical, columns=[c for c in listing_categorical.columns if c != 'listing_id'], \n",
    "                                      prefix_sep='_', drop_first=False)\n",
    "\n",
    "print(f\"   Created {len(features_categorical.columns) - 1} categorical features (one-hot encoded)\")\n",
    "print(f\"   Shape: {features_categorical.shape}\")\n",
    "\n",
    "# Merge with numerical features\n",
    "features_combined = features_numerical.merge(features_categorical, on='listing_id', how='left')\n",
    "features_combined = features_combined.fillna(0)\n",
    "\n",
    "print(f\"\\nCombined features (numerical + categorical): {features_combined.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed424d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 5: FEATURE ENGINEERING - TEMPORAL FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE ENGINEERING: TEMPORAL FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create temporal features from calendar data\n",
    "# For each listing-date combination, extract temporal features\n",
    "calendar_temporal = calendar[['listing_id', 'date']].copy()\n",
    "calendar_temporal['year'] = calendar_temporal['date'].dt.year\n",
    "calendar_temporal['month'] = calendar_temporal['date'].dt.month\n",
    "calendar_temporal['day_of_month'] = calendar_temporal['date'].dt.day\n",
    "calendar_temporal['day_of_week'] = calendar_temporal['date'].dt.dayofweek\n",
    "calendar_temporal['is_weekend'] = (calendar_temporal['day_of_week'] >= 5).astype(int)\n",
    "calendar_temporal['is_month_start'] = (calendar_temporal['day_of_month'] <= 3).astype(int)\n",
    "calendar_temporal['is_month_end'] = (calendar_temporal['day_of_month'] >= 28).astype(int)\n",
    "\n",
    "# Extract quarter\n",
    "calendar_temporal['quarter'] = calendar_temporal['date'].dt.quarter\n",
    "\n",
    "# For the final dataset, we'll merge these temporal features with calendar\n",
    "# But first, let's create aggregated temporal patterns per listing\n",
    "temporal_patterns = calendar.groupby('listing_id').agg({\n",
    "    'is_weekend': 'mean',  # Weekend availability preference\n",
    "    'month': lambda x: x.mode()[0] if len(x.mode()) > 0 else 0,  # Most common month\n",
    "    'day_of_week': lambda x: x.mode()[0] if len(x.mode()) > 0 else 0  # Most common day\n",
    "}).reset_index()\n",
    "temporal_patterns.columns = ['listing_id', 'weekend_preference', 'preferred_month', 'preferred_day']\n",
    "\n",
    "print(f\"   Created {len(temporal_patterns.columns) - 1} aggregated temporal pattern features\")\n",
    "\n",
    "# Merge temporal patterns\n",
    "features_combined = features_combined.merge(temporal_patterns, on='listing_id', how='left')\n",
    "features_combined = features_combined.fillna(0)\n",
    "\n",
    "print(f\"Features after adding temporal patterns: {features_combined.shape}\")\n",
    "\n",
    "# Note: When creating the final dataset, we'll add date-specific temporal features\n",
    "# to each calendar row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821df17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 6: FEATURE ENGINEERING - TEXTUAL FEATURES (TF-IDF)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE ENGINEERING: TEXTUAL FEATURES (TF-IDF)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. TF-IDF on listing descriptions\n",
    "text_columns = ['name', 'description', 'neighborhood_overview']\n",
    "available_text_cols = [col for col in text_columns if col in listings_df.columns]\n",
    "\n",
    "print(f\"\\nProcessing text columns: {available_text_cols}\")\n",
    "\n",
    "# Combine text columns\n",
    "listings_df['combined_text'] = listings_df[available_text_cols].fillna('').apply(\n",
    "    lambda row: ' '.join(row.astype(str)), axis=1\n",
    ")\n",
    "\n",
    "# Remove HTML tags and clean text\n",
    "import re\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = str(text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text.lower()\n",
    "\n",
    "listings_df['combined_text_clean'] = listings_df['combined_text'].apply(clean_text)\n",
    "\n",
    "# Create TF-IDF features (limit to top 50 features to avoid too many dimensions)\n",
    "print(\"\\nCreating TF-IDF features from listing descriptions...\")\n",
    "tfidf = TfidfVectorizer(max_features=50, stop_words='english', ngram_range=(1, 2))\n",
    "tfidf_features = tfidf.fit_transform(listings_df['combined_text_clean'])\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_features.toarray(),\n",
    "    columns=[f'tfidf_desc_{i}' for i in range(tfidf_features.shape[1])],\n",
    "    index=listings_df.index\n",
    ")\n",
    "tfidf_df['listing_id'] = listings_df['listing_id'].values\n",
    "\n",
    "print(f\"   Created {len(tfidf_df.columns) - 1} TF-IDF features from descriptions\")\n",
    "\n",
    "# 2. TF-IDF on review comments\n",
    "print(\"\\nCreating TF-IDF features from review comments...\")\n",
    "\n",
    "# Aggregate reviews per listing\n",
    "reviews_agg = reviews_df.groupby('listing_id')['comments'].apply(\n",
    "    lambda x: ' '.join(x.fillna('').astype(str))\n",
    ").reset_index()\n",
    "reviews_agg['comments_clean'] = reviews_agg['comments'].apply(clean_text)\n",
    "\n",
    "# Create TF-IDF for reviews (top 30 features)\n",
    "tfidf_reviews = TfidfVectorizer(max_features=30, stop_words='english', ngram_range=(1, 2))\n",
    "tfidf_reviews_features = tfidf_reviews.fit_transform(reviews_agg['comments_clean'])\n",
    "\n",
    "tfidf_reviews_df = pd.DataFrame(\n",
    "    tfidf_reviews_features.toarray(),\n",
    "    columns=[f'tfidf_review_{i}' for i in range(tfidf_reviews_features.shape[1])],\n",
    "    index=reviews_agg.index\n",
    ")\n",
    "tfidf_reviews_df['listing_id'] = reviews_agg['listing_id'].values\n",
    "\n",
    "print(f\"   Created {len(tfidf_reviews_df.columns) - 1} TF-IDF features from reviews\")\n",
    "\n",
    "# Merge TF-IDF features\n",
    "features_combined = features_combined.merge(tfidf_df, on='listing_id', how='left')\n",
    "features_combined = features_combined.merge(tfidf_reviews_df, on='listing_id', how='left')\n",
    "features_combined = features_combined.fillna(0)\n",
    "\n",
    "print(f\"\\nFeatures after adding TF-IDF: {features_combined.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92677c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 7: ADDITIONAL FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE ENGINEERING: ADDITIONAL DERIVED FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Review-based features\n",
    "print(\"\\nCreating review-based features...\")\n",
    "\n",
    "review_stats = reviews_df.groupby('listing_id').agg({\n",
    "    'id': 'count',  # Total number of reviews\n",
    "    'date': ['min', 'max']  # First and last review dates\n",
    "}).reset_index()\n",
    "review_stats.columns = ['listing_id', 'total_reviews_count', 'first_review_date', 'last_review_date']\n",
    "\n",
    "# Convert dates\n",
    "review_stats['first_review_date'] = pd.to_datetime(review_stats['first_review_date'])\n",
    "review_stats['last_review_date'] = pd.to_datetime(review_stats['last_review_date'])\n",
    "\n",
    "# Calculate review recency (days since last review)\n",
    "current_date = pd.to_datetime('2025-06-17')  # Approximate current date based on scrape date\n",
    "review_stats['days_since_last_review'] = (current_date - review_stats['last_review_date']).dt.days\n",
    "review_stats['review_span_days'] = (review_stats['last_review_date'] - review_stats['first_review_date']).dt.days\n",
    "review_stats['reviews_per_day'] = review_stats['total_reviews_count'] / (review_stats['review_span_days'] + 1)\n",
    "\n",
    "# Fill missing values\n",
    "review_stats = review_stats.fillna(0)\n",
    "\n",
    "# Select only numerical columns for merging\n",
    "review_features = review_stats[['listing_id', 'total_reviews_count', 'days_since_last_review', \n",
    "                                'review_span_days', 'reviews_per_day']].copy()\n",
    "\n",
    "features_combined = features_combined.merge(review_features, on='listing_id', how='left')\n",
    "features_combined = features_combined.fillna(0)\n",
    "\n",
    "print(f\"   Created {len(review_features.columns) - 1} review-based features\")\n",
    "\n",
    "# 2. Price-related features\n",
    "print(\"\\nCreating price-related features...\")\n",
    "if 'price' in features_combined.columns:\n",
    "    # Price per person (if accommodates available)\n",
    "    if 'accommodates' in features_combined.columns:\n",
    "        features_combined['price_per_person'] = features_combined['price'] / (features_combined['accommodates'] + 1)\n",
    "    \n",
    "    # Price per bedroom\n",
    "    if 'bedrooms' in features_combined.columns:\n",
    "        features_combined['price_per_bedroom'] = features_combined['price'] / (features_combined['bedrooms'] + 1)\n",
    "    \n",
    "    # Price per bed\n",
    "    if 'beds' in features_combined.columns:\n",
    "        features_combined['price_per_bed'] = features_combined['price'] / (features_combined['beds'] + 1)\n",
    "\n",
    "# 3. Host experience features\n",
    "print(\"\\nCreating host experience features...\")\n",
    "if 'calculated_host_listings_count' in features_combined.columns:\n",
    "    features_combined['is_superhost_candidate'] = (\n",
    "        (features_combined['calculated_host_listings_count'] >= 5) & \n",
    "        (features_combined.get('number_of_reviews', 0) >= 20)\n",
    "    ).astype(int)\n",
    "\n",
    "# 4. Availability features\n",
    "if 'availability_365' in features_combined.columns:\n",
    "    features_combined['availability_rate_365'] = features_combined['availability_365'] / 365\n",
    "\n",
    "print(f\"\\nFinal feature set shape: {features_combined.shape}\")\n",
    "print(f\"Total features: {len(features_combined.columns) - 1}\")  # -1 for listing_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec353a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 8: CREATE UNIFIED ML-READY DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CREATING UNIFIED ML-READY DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# The target variable is availability for each listing-date combination\n",
    "# We'll merge calendar data with all engineered features\n",
    "\n",
    "# Prepare calendar with target variable\n",
    "calendar_ml = calendar[['listing_id', 'date', 'available_bool']].copy()\n",
    "calendar_ml['target'] = calendar_ml['available_bool'].astype(int)\n",
    "\n",
    "# Add temporal features to calendar\n",
    "calendar_ml['year'] = calendar_ml['date'].dt.year\n",
    "calendar_ml['month'] = calendar_ml['date'].dt.month\n",
    "calendar_ml['day_of_month'] = calendar_ml['date'].dt.day\n",
    "calendar_ml['day_of_week'] = calendar_ml['date'].dt.dayofweek\n",
    "calendar_ml['is_weekend'] = (calendar_ml['day_of_week'] >= 5).astype(int)\n",
    "calendar_ml['quarter'] = calendar_ml['date'].dt.quarter\n",
    "calendar_ml['is_month_start'] = (calendar_ml['day_of_month'] <= 3).astype(int)\n",
    "calendar_ml['is_month_end'] = (calendar_ml['day_of_month'] >= 28).astype(int)\n",
    "\n",
    "# Calculate days from a reference date (for seasonality)\n",
    "reference_date = calendar_ml['date'].min()\n",
    "calendar_ml['days_from_start'] = (calendar_ml['date'] - reference_date).dt.days\n",
    "\n",
    "print(f\"\\nCalendar shape: {calendar_ml.shape}\")\n",
    "\n",
    "# Merge with engineered features\n",
    "ml_dataset = calendar_ml.merge(features_combined, on='listing_id', how='left')\n",
    "\n",
    "# Fill any remaining missing values\n",
    "ml_dataset = ml_dataset.fillna(0)\n",
    "\n",
    "print(f\"\\nML Dataset shape: {ml_dataset.shape}\")\n",
    "print(f\"Total features: {len(ml_dataset.columns)}\")\n",
    "print(f\"Target variable: 'target' (1 = available, 0 = not available)\")\n",
    "\n",
    "# Check final missing values\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL MISSING VALUES CHECK\")\n",
    "print(\"=\" * 80)\n",
    "missing_final = ml_dataset.isnull().sum()\n",
    "missing_final = missing_final[missing_final > 0]\n",
    "if len(missing_final) > 0:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_final)\n",
    "else:\n",
    "    print(\"✓ No missing values in final dataset!\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA TYPES SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(ml_dataset.dtypes.value_counts())\n",
    "\n",
    "# Display sample\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE OF ML-READY DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(ml_dataset.head())\n",
    "print(f\"\\nDataset shape: {ml_dataset.shape}\")\n",
    "print(f\"Columns: {list(ml_dataset.columns[:10])}... (showing first 10)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 9: FINAL VALIDATION AND SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL VALIDATION AND SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Check for any infinite values\n",
    "inf_cols = []\n",
    "for col in ml_dataset.select_dtypes(include=[np.number]).columns:\n",
    "    if np.isinf(ml_dataset[col]).any():\n",
    "        inf_cols.append(col)\n",
    "        ml_dataset[col] = ml_dataset[col].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "if inf_cols:\n",
    "    print(f\"✓ Replaced infinite values in {len(inf_cols)} columns\")\n",
    "else:\n",
    "    print(\"✓ No infinite values found\")\n",
    "\n",
    "# 2. Check target distribution\n",
    "print(\"\\nTarget Variable Distribution:\")\n",
    "target_dist = ml_dataset['target'].value_counts()\n",
    "print(target_dist)\n",
    "print(f\"   Available (1): {target_dist.get(1, 0):,} ({target_dist.get(1, 0)/len(ml_dataset)*100:.2f}%)\")\n",
    "print(f\"   Not Available (0): {target_dist.get(0, 0):,} ({target_dist.get(0, 0)/len(ml_dataset)*100:.2f}%)\")\n",
    "\n",
    "# 3. Feature categories summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE CATEGORIES SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "feature_categories = {\n",
    "    'Temporal': [col for col in ml_dataset.columns if col in ['year', 'month', 'day_of_month', 'day_of_week', \n",
    "                                                               'is_weekend', 'quarter', 'is_month_start', \n",
    "                                                               'is_month_end', 'days_from_start']],\n",
    "    'Numerical (Listings)': [col for col in ml_dataset.columns if col in numerical_features],\n",
    "    'Numerical (Calendar Aggregates)': [col for col in ml_dataset.columns if 'avg_' in col or 'total_' in col or \n",
    "                                        'median_' in col or 'min_' in col or 'max_' in col or 'std' in col],\n",
    "    'Categorical (One-hot)': [col for col in ml_dataset.columns if any(cat in col for cat in categorical_features)],\n",
    "    'TF-IDF (Descriptions)': [col for col in ml_dataset.columns if 'tfidf_desc' in col],\n",
    "    'TF-IDF (Reviews)': [col for col in ml_dataset.columns if 'tfidf_review' in col],\n",
    "    'Review-based': [col for col in ml_dataset.columns if 'review' in col.lower() and 'tfidf' not in col],\n",
    "    'Price-derived': [col for col in ml_dataset.columns if 'price_per' in col],\n",
    "    'Other': []\n",
    "}\n",
    "\n",
    "# Categorize remaining columns\n",
    "all_categorized = set()\n",
    "for cat, cols in feature_categories.items():\n",
    "    all_categorized.update(cols)\n",
    "\n",
    "other_cols = [col for col in ml_dataset.columns if col not in all_categorized \n",
    "              and col not in ['listing_id', 'date', 'available_bool', 'target']]\n",
    "feature_categories['Other'] = other_cols\n",
    "\n",
    "for category, features in feature_categories.items():\n",
    "    if features:\n",
    "        print(f\"\\n{category}: {len(features)} features\")\n",
    "        if len(features) <= 10:\n",
    "            print(f\"   {features}\")\n",
    "        else:\n",
    "            print(f\"   {features[:5]} ... and {len(features)-5} more\")\n",
    "\n",
    "# 4. Save the dataset\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING ML-READY DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Remove non-feature columns for ML (keep listing_id and date for reference if needed)\n",
    "ml_features = ml_dataset.drop(['available_bool'], axis=1, errors='ignore')\n",
    "\n",
    "# Optionally save to CSV (commented out to avoid large files)\n",
    "# ml_features.to_csv('ml_ready_dataset.csv', index=False)\n",
    "# print(\"✓ Dataset saved to 'ml_ready_dataset.csv'\")\n",
    "\n",
    "print(f\"\\n✓ ML-ready dataset created successfully!\")\n",
    "print(f\"   Shape: {ml_features.shape}\")\n",
    "print(f\"   Features: {len(ml_features.columns) - 3}\")  # Excluding listing_id, date, target\n",
    "print(f\"   Target: 'target' (availability: 1 = available, 0 = not available)\")\n",
    "\n",
    "# Display final statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total rows: {len(ml_features):,}\")\n",
    "print(f\"Total columns: {len(ml_features.columns)}\")\n",
    "print(f\"Unique listings: {ml_features['listing_id'].nunique():,}\")\n",
    "print(f\"Date range: {ml_features['date'].min()} to {ml_features['date'].max()}\")\n",
    "print(f\"Memory usage: {ml_features.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 10: FINAL EDA VISUALIZATION - FEATURE IMPORTANCE PREVIEW\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL EDA: CORRELATION WITH TARGET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate correlation of numerical features with target\n",
    "numerical_cols = ml_dataset.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Remove non-feature columns\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['listing_id', 'target', 'available_bool']]\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = []\n",
    "for col in numerical_cols[:50]:  # Limit to first 50 to avoid too many\n",
    "    try:\n",
    "        corr = ml_dataset[col].corr(ml_dataset['target'])\n",
    "        if not np.isnan(corr):\n",
    "            correlations.append({'feature': col, 'correlation': abs(corr)})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('correlation', ascending=False).head(20)\n",
    "\n",
    "if len(corr_df) > 0:\n",
    "    fig = px.bar(\n",
    "        corr_df,\n",
    "        x='correlation',\n",
    "        y='feature',\n",
    "        orientation='h',\n",
    "        title='Top 20 Features by Absolute Correlation with Target (Availability)',\n",
    "        labels={'correlation': 'Absolute Correlation', 'feature': 'Feature'}\n",
    "    )\n",
    "    fig.update_layout(height=600, yaxis={'categoryorder': 'total ascending'})\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\nTop 10 features most correlated with availability:\")\n",
    "    print(corr_df.head(10)[['feature', 'correlation']].to_string(index=False))\n",
    "else:\n",
    "    print(\"Could not calculate correlations\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ EXERCISE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"  • EDA: Comprehensive exploratory data analysis with Plotly visualizations\")\n",
    "print(f\"  • Numerical Features: Extracted and engineered from listings and calendar\")\n",
    "print(f\"  • Categorical Features: One-hot encoded from listings attributes\")\n",
    "print(f\"  • Temporal Features: Day, week, month, season patterns\")\n",
    "print(f\"  • Textual Features: TF-IDF from descriptions ({50} features) and reviews ({30} features)\")\n",
    "print(f\"  • Additional Features: Review statistics, price ratios, host metrics\")\n",
    "print(f\"  • Final Dataset: {ml_features.shape[0]:,} rows × {ml_features.shape[1]} columns\")\n",
    "print(f\"  • Target Variable: 'target' (1 = available, 0 = not available)\")\n",
    "print(f\"  • Missing Values: All handled (filled with appropriate defaults)\")\n",
    "print(f\"  • Data Quality: Cleaned and validated\")\n",
    "print(\"\\nThe dataset is now ready for machine learning model training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784999f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
